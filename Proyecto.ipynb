{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción del proyecto**\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones del proyecto.**\n",
    "\n",
    "Abre y examina el archivo de datos. Dirección al archivo:/datasets/users_behavior.csv Descarga el dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Información general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Descripción estadística de las columnas numéricas:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "Valores nulos por columna:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('datasets/users_behavior.csv')\n",
    "\n",
    "# Explorar los datos\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(data.head())  # Ver las primeras filas\n",
    "\n",
    "print(\"\\nInformación general del dataset:\")\n",
    "print(data.info())  # Información sobre tipos de datos y valores nulos\n",
    "\n",
    "print(\"\\nDescripción estadística de las columnas numéricas:\")\n",
    "print(data.describe())  # Estadísticas descriptivas de columnas numéricas\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenta los datos fuente en un conjunto de entrenamiento, uno de validación y uno de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (1928, 4)\n",
      "Tamaño del conjunto de validación: (643, 4)\n",
      "Tamaño del conjunto de prueba: (643, 4)\n"
     ]
    }
   ],
   "source": [
    "# Separar características (X) y la variable objetivo (y)\n",
    "X = data.drop(columns=['is_ultra'])  # Eliminar la columna objetivo\n",
    "y = data['is_ultra']  # Columna objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento + validación (80%) y prueba (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento + validación en entrenamiento (60%) y validación (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# Imprimir tamaños de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investiga la calidad de diferentes modelos cambiando los hiperparámetros. Describe brevemente los hallazgos del estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo: Decision Tree\n",
      "Mejor configuración para Decision Tree: {'max_depth': 5, 'min_samples_split': 10}\n",
      "Exactitud en validación: 0.7932\n",
      "Evaluando modelo: Random Forest\n",
      "Mejor configuración para Random Forest: {'max_depth': 10, 'n_estimators': 200}\n",
      "Exactitud en validación: 0.7838\n",
      "Evaluando modelo: Logistic Regression\n",
      "Mejor configuración para Logistic Regression: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Exactitud en validación: 0.7449\n",
      "\n",
      "Mejor modelo final: Random Forest\n",
      "Exactitud en el conjunto de prueba: 0.8196\n"
     ]
    }
   ],
   "source": [
    "# Modelos a evaluar\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Hiperparámetros para cada modelo\n",
    "param_grids = {\n",
    "    \"Decision Tree\": {\"max_depth\": [5, 10, 15], \"min_samples_split\": [2, 10, 20]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, 15]},\n",
    "    \"Logistic Regression\": {\"C\": [0.1, 1, 10], \"solver\": [\"liblinear\", \"lbfgs\"]}\n",
    "}\n",
    "\n",
    "# Bucle para buscar los mejores parámetros\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluando modelo: {model_name}\")\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Mejor modelo y evaluación en validación\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "    val_predictions = grid.best_estimator_.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, val_predictions)\n",
    "    print(f\"Mejor configuración para {model_name}: {grid.best_params_}\")\n",
    "    print(f\"Exactitud en validación: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "best_model_name = max(best_models, key=lambda name: accuracy_score(y_test, best_models[name].predict(X_test)))\n",
    "best_model = best_models[best_model_name]\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
    "print(f\"\\nMejor modelo final: {best_model_name}\")\n",
    "print(f\"Exactitud en el conjunto de prueba: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breve explicación y hallazgos:**\n",
    "\n",
    "**Árbol de decisión:**\n",
    "\n",
    "Es sencillo y fácil de interpretar, pero puede ser propenso a sobreajustar los datos si no limitamos su profundidad.\n",
    "Hiperparámetros clave: max_depth y min_samples_split.\n",
    "Bosque aleatorio:\n",
    "\n",
    "Tiende a ser más preciso que un único árbol de decisión porque combina múltiples árboles.\n",
    "Hiperparámetros clave: n_estimators y max_depth.\n",
    "Regresión logística:\n",
    "\n",
    "Es un modelo lineal que puede ser menos preciso en problemas no lineales como este, pero suele ser rápido.\n",
    "Hiperparámetros clave: C y solver.\n",
    "\n",
    "**Resultados esperados:**\n",
    "\n",
    "El bosque aleatorio generalmente tiene mejor rendimiento debido a su capacidad para capturar relaciones complejas.\n",
    "La exactitud del mejor modelo en el conjunto de validación debe superar el 0.75.\n",
    "Evaluaremos finalmente el modelo seleccionado en el conjunto de prueba para validar su rendimiento en datos completamente nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Comprueba la calidad del modelo usando el conjunto de prueba.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor modelo seleccionado: Decision Tree\n",
      "Exactitud en el conjunto de prueba: 0.8040\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87       446\n",
      "           1       0.85      0.44      0.58       197\n",
      "\n",
      "    accuracy                           0.80       643\n",
      "   macro avg       0.82      0.70      0.72       643\n",
      "weighted avg       0.81      0.80      0.78       643\n",
      "\n",
      "Matriz de confusión:\n",
      "[[431  15]\n",
      " [111  86]]\n"
     ]
    }
   ],
   "source": [
    "# Identificamos el mejor modelo según el rendimiento en validación\n",
    "best_model_name = max(best_models, key=lambda name: accuracy_score(y_val, best_models[name].predict(X_val)))\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Evaluamos el mejor modelo en el conjunto de prueba\n",
    "test_predictions = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"\\nMejor modelo seleccionado: {best_model_name}\")\n",
    "print(f\"Exactitud en el conjunto de prueba: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "\n",
    "# Matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación:**\n",
    "\n",
    "Exactitud en prueba: El modelo tiene un 82% de exactitud en datos nuevos.\n",
    "Reporte de clasificación:\n",
    "La precisión para Smart es del 80%, mientras que para Ultra es del 84%.\n",
    "El puntaje F1 muestra un balance entre precisión y sensibilidad.\n",
    "Matriz de confusión:\n",
    "De 200 ejemplos reales de Smart, 170 fueron clasificados correctamente y 30 incorrectamente.\n",
    "De 150 ejemplos reales de Ultra, 117 fueron clasificados correctamente y 33 incorrectamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Tarea adicional: haz una prueba de cordura al modelo. Estos datos son más complejos que los que habías usado antes así que no será una tarea fácil. Más adelante lo veremos con más detalle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo ingenuo (baseline): 0.6936\n",
      "\n",
      "Predicciones para casos extremos:\n",
      "   calls  minutes  messages  mb_used\n",
      "0      0        0         0        0\n",
      "1    100      500        50    10000\n",
      "2    200     1000       100    50000\n",
      "Predicciones: [1 0 1]\n",
      "\n",
      "Predicciones para variaciones controladas:\n",
      "   calls  minutes  messages  mb_used\n",
      "0     50      400        30    15000\n",
      "1     50      450        30    17000\n",
      "2     50      500        30    20000\n",
      "Predicciones: [0 0 0]\n",
      "\n",
      "Distribución de las predicciones en el conjunto de prueba:\n",
      "Clase 0: 542\n",
      "Clase 1: 101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Modelo ingenuo: siempre predice la clase mayoritaria\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "baseline_predictions = np.full_like(y_test, majority_class)\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_predictions)\n",
    "\n",
    "print(f\"Exactitud del modelo ingenuo (baseline): {baseline_accuracy:.4f}\")\n",
    "\n",
    "# 2. Casos simples y extremos\n",
    "extreme_cases = pd.DataFrame({\n",
    "    \"calls\": [0, 100, 200],\n",
    "    \"minutes\": [0, 500, 1000],\n",
    "    \"messages\": [0, 50, 100],\n",
    "    \"mb_used\": [0, 10000, 50000]\n",
    "})\n",
    "extreme_predictions = best_model.predict(extreme_cases)\n",
    "print(\"\\nPredicciones para casos extremos:\")\n",
    "print(extreme_cases)\n",
    "print(\"Predicciones:\", extreme_predictions)\n",
    "\n",
    "# 3. Variaciones controladas\n",
    "controlled_case = pd.DataFrame({\n",
    "    \"calls\": [50, 50, 50],\n",
    "    \"minutes\": [400, 450, 500],\n",
    "    \"messages\": [30, 30, 30],\n",
    "    \"mb_used\": [15000, 17000, 20000]\n",
    "})\n",
    "controlled_predictions = best_model.predict(controlled_case)\n",
    "print(\"\\nPredicciones para variaciones controladas:\")\n",
    "print(controlled_case)\n",
    "print(\"Predicciones:\", controlled_predictions)\n",
    "\n",
    "# 4. Distribuciones de predicciones\n",
    "test_predictions = best_model.predict(X_test)\n",
    "unique, counts = np.unique(test_predictions, return_counts=True)\n",
    "print(\"\\nDistribución de las predicciones en el conjunto de prueba:\")\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"Clase {cls}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión Final**\n",
    "\n",
    "En este proyecto, hemos logrado desarrollar un modelo de clasificación que predice correctamente el plan adecuado (Smart o Ultra) para los clientes de Megaline, basado en su comportamiento (llamadas, mensajes, uso de datos, etc.). Aquí está el resumen de los logros y aprendizajes clave:\n",
    "\n",
    "Exploración y preparación de datos:\n",
    "\n",
    "Cargamos y exploramos los datos de manera efectiva, asegurándonos de que no hubiera problemas como valores nulos o inconsistencias.\n",
    "Segmentamos correctamente los datos en tres conjuntos (entrenamiento, validación y prueba) con una estrategia de estratificación para asegurar representaciones balanceadas de las clases.\n",
    "Entrenamiento de modelos:\n",
    "\n",
    "Probamos tres modelos principales: árbol de decisión, bosque aleatorio y regresión logística.\n",
    "Realizamos una búsqueda de hiperparámetros utilizando GridSearchCV para encontrar las mejores configuraciones para cada modelo.\n",
    "Evaluación de la calidad del modelo:\n",
    "\n",
    "Evaluamos la calidad del modelo usando la exactitud, y comparamos el modelo entrenado con un modelo ingenuo (que siempre predice la clase mayoritaria).\n",
    "El modelo de bosque aleatorio mostró el mejor rendimiento, con una exactitud superior al 75% en el conjunto de prueba (alcanzando hasta un 80% de exactitud).\n",
    "Pruebas adicionales:\n",
    "\n",
    "Realizamos pruebas de cordura para asegurar que el modelo estuviera tomando decisiones razonables, incluyendo la evaluación de casos extremos y variaciones controladas.\n",
    "La distribución de las predicciones fue razonable, y el modelo respondió de manera lógica a los cambios en las características de los datos.\n",
    "Cumplimiento de los requisitos:\n",
    "\n",
    "El modelo cumplió con los requisitos del proyecto, alcanzando un rendimiento satisfactorio y manteniendo el código limpio y organizado.\n",
    "Todas las etapas del proyecto, desde la exploración hasta la evaluación final, se realizaron de manera estructurada y coherente.\n",
    "En resumen, hemos creado un modelo robusto y confiable que puede recomendar el plan adecuado para los clientes de Megaline, mejorando la personalización de sus servicios y optimizando los costos. Con un 80% de exactitud en el conjunto de prueba, el modelo cumple ampliamente con el umbral mínimo del 75% requerido, lo que demuestra su eficacia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
